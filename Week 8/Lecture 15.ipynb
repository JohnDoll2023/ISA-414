{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISA 414 - Managing Big Data\n",
    "## Lecture 15 – Text Mining (Part II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/29/2017 23:49</td>\n",
       "      <td>I absolutely agree in the drive to respect the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/29/2017 23:44</td>\n",
       "      <td>Thank you Starbucks and Mr. Schultz for suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/29/2017 23:11</td>\n",
       "      <td>Very unhappy with my last few visits to the ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/29/2017 22:30</td>\n",
       "      <td>It seems to have very limited selection at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/29/2017 22:19</td>\n",
       "      <td>So here it is â almost the end of January â...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1/31/2017 0:02</td>\n",
       "      <td>Stick to making coffee. If I wanted politics m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1/31/2017 0:02</td>\n",
       "      <td>THANK YOU FOR SUPPORTING IMMIGRATION TO THE US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1/31/2017 0:01</td>\n",
       "      <td>I have been a Gold rewards club member for 8 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1/31/2017 0:01</td>\n",
       "      <td>Thank you for your stance on refugees. I norma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1/31/2017 0:00</td>\n",
       "      <td>I will never visit  your stores again</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1777 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time                                            message\n",
       "0     1/29/2017 23:49  I absolutely agree in the drive to respect the...\n",
       "1     1/29/2017 23:44  Thank you Starbucks and Mr. Schultz for suppor...\n",
       "2     1/29/2017 23:11  Very unhappy with my last few visits to the ma...\n",
       "3     1/29/2017 22:30  It seems to have very limited selection at the...\n",
       "4     1/29/2017 22:19  So here it is â almost the end of January â...\n",
       "...               ...                                                ...\n",
       "1772   1/31/2017 0:02  Stick to making coffee. If I wanted politics m...\n",
       "1773   1/31/2017 0:02  THANK YOU FOR SUPPORTING IMMIGRATION TO THE US...\n",
       "1774   1/31/2017 0:01  I have been a Gold rewards club member for 8 y...\n",
       "1775   1/31/2017 0:01  Thank you for your stance on refugees. I norma...\n",
       "1776   1/31/2017 0:00              I will never visit  your stores again\n",
       "\n",
       "[1777 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "raw_data = pandas.read_csv(\"starbucks.csv\", encoding='latin')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 117)\t0.09534625892455924\n",
      "  (0, 204)\t0.09534625892455924\n",
      "  (0, 2184)\t0.28603877677367767\n",
      "  (0, 4236)\t0.19069251784911848\n",
      "  (0, 1348)\t0.09534625892455924\n",
      "  (0, 4301)\t0.28603877677367767\n",
      "  (0, 3552)\t0.09534625892455924\n",
      "  (0, 3609)\t0.09534625892455924\n",
      "  (0, 278)\t0.19069251784911848\n",
      "  (0, 1759)\t0.09534625892455924\n",
      "  (0, 2891)\t0.09534625892455924\n",
      "  (0, 1524)\t0.09534625892455924\n",
      "  (0, 2092)\t0.09534625892455924\n",
      "  (0, 4679)\t0.09534625892455924\n",
      "  (0, 298)\t0.19069251784911848\n",
      "  (0, 893)\t0.19069251784911848\n",
      "  (0, 4202)\t0.09534625892455924\n",
      "  (0, 2628)\t0.09534625892455924\n",
      "  (0, 4234)\t0.09534625892455924\n",
      "  (0, 255)\t0.09534625892455924\n",
      "  (0, 2855)\t0.28603877677367767\n",
      "  (0, 4626)\t0.09534625892455924\n",
      "  (0, 366)\t0.09534625892455924\n",
      "  (0, 1063)\t0.19069251784911848\n",
      "  (0, 2136)\t0.09534625892455924\n",
      "  :\t:\n",
      "  (1774, 4143)\t0.09805806756909202\n",
      "  (1775, 4301)\t0.23570226039551587\n",
      "  (1775, 4708)\t0.23570226039551587\n",
      "  (1775, 2920)\t0.23570226039551587\n",
      "  (1775, 1712)\t0.23570226039551587\n",
      "  (1775, 4005)\t0.23570226039551587\n",
      "  (1775, 654)\t0.23570226039551587\n",
      "  (1775, 4227)\t0.23570226039551587\n",
      "  (1775, 4791)\t0.23570226039551587\n",
      "  (1775, 4794)\t0.23570226039551587\n",
      "  (1775, 407)\t0.23570226039551587\n",
      "  (1775, 2865)\t0.23570226039551587\n",
      "  (1775, 3461)\t0.23570226039551587\n",
      "  (1775, 3991)\t0.23570226039551587\n",
      "  (1775, 461)\t0.23570226039551587\n",
      "  (1775, 4395)\t0.23570226039551587\n",
      "  (1775, 3482)\t0.23570226039551587\n",
      "  (1775, 3054)\t0.23570226039551587\n",
      "  (1775, 2851)\t0.23570226039551587\n",
      "  (1776, 4708)\t0.4082482904638631\n",
      "  (1776, 196)\t0.4082482904638631\n",
      "  (1776, 4055)\t0.4082482904638631\n",
      "  (1776, 4794)\t0.4082482904638631\n",
      "  (1776, 2820)\t0.4082482904638631\n",
      "  (1776, 4577)\t0.4082482904638631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer   = TfidfVectorizer(use_idf = False)\n",
    "tf_values = vectorizer.fit_transform(raw_data[\"message\"])\n",
    "print(tf_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 117  204 2184 4236 1348 4301 3552 3609  278 1759 2891 1524 2092 4679\n",
      "  298  893 4202 2628 4234  255 2855 4626  366 1063 2136 1284  480 1525\n",
      " 4249 4708 2748 2920 4625  454 2686 1705 1712 1910 2953 2543 4005  848\n",
      "  654 1662  290  592 1432 1870 2558  632 1054  355 2753 3703 3835 1729]\n",
      "['absolutely', 'agree', 'in', 'the', 'drive', 'to', 'respect', 'rights', 'and', 'freedom', 'of', 'everyone', 'however', 'when', 'any', 'company', 'tells', 'me', 'that', 'am', 'not', 'wanted', 'as', 'customer', 'if', 'do', 'believe', 'everything', 'they', 'will', 'move', 'on', 'want', 'be', 'mindless', 'follower', 'for', 'group', 'or', 'love', 'starbucks', 'coffee', 'but', 'find', 'another', 'brand', 'embrace', 'good', 'luck', 'building', 'cult', 'around', 'mr', 'schultz', 'signed', 'former']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "all_word_names  = vectorizer.get_feature_names()\n",
    "\n",
    "# nonzero() returns two rows. The first one contains the document index. The second one contains the word (column) indexes. We are interested in the latter. Hence, the [1]\n",
    "doc0_word_index = tf_values[0,:].nonzero()[1]\n",
    "print(doc0_word_index)\n",
    "\n",
    "doc0_word_names = [all_word_names[w] for w in doc0_word_index]\n",
    "print(doc0_word_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitlines() remove the breakline character \\n from each list of words\n",
    "file = open('positive-words.txt', 'r')\n",
    "positive_words = file.read().splitlines() \n",
    "\n",
    "file = open('negative-words.txt', 'r')\n",
    "negative_words = file.read().splitlines() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'to', 'and', 'of', 'as', 'want', 'for', 'starbucks', 'thank', 'you', 'your', 'service', 'time', 'business', 'corporation', 'refugees', 'hope', 'wife', 'uniformed', 'member', 'applaud', 'pledge', 'employ', 'ray', 'frightening', 'demonstrating', 'humanity', 'realm']\n"
     ]
    }
   ],
   "source": [
    "# words in document 80\n",
    "doc80_word_index = tf_values[79,:].nonzero()[1]\n",
    "doc80_word_names = [all_word_names[w] for w in doc80_word_index]\n",
    "\n",
    "print(doc80_word_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# counting the number of times each word in document 80 occurs in the positive and negative lists of words\n",
    "count_positive_words = [positive_words.count(word) for word in doc80_word_names]\n",
    "count_negative_words = [negative_words.count(word) for word in doc80_word_names]\n",
    "\n",
    "# taking the difference between the sum of the above counts\n",
    "score = sum(count_positive_words) - sum(count_negative_words)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'and', 'of', 'me', 'that', 'will', 'for', 'starbucks', 'but', 'have', 'over', 'your', '10', 'been', 'no', 'point', 'management', 'products', 'by', 'longer', 'years', 'loyal', 'recent', 'comments', 'unfortunately', 'consumer', 'events', 'upper', 'disgusted', 'use']\n"
     ]
    }
   ],
   "source": [
    "# words in document 248\n",
    "doc248_word_index = tf_values[247,:].nonzero()[1]\n",
    "doc248_word_names = [all_word_names[w] for w in doc248_word_index]\n",
    "\n",
    "print(doc248_word_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "# counting the number of times each word in document 248 occurs in the positive and negative lists of words\n",
    "count_positive_words = [positive_words.count(word) for word in doc248_word_names]\n",
    "count_negative_words = [negative_words.count(word) for word in doc248_word_names]\n",
    "\n",
    "# taking the difference between the sum of the above counts\n",
    "score = sum(count_positive_words) - sum(count_negative_words)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 22 - we won't need the previous variables anymore. You can hit the Restart button to release the memory used by them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "raw_data = pandas.read_csv(\"IMDB.csv\")\n",
    "\n",
    "#vectorizer   = TfidfVectorizer(stop_words = \"english\")\n",
    "vectorizer   = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_values = vectorizer.fit_transform(raw_data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 am</th>\n",
       "      <th>00 feet</th>\n",
       "      <th>00 for</th>\n",
       "      <th>00 if</th>\n",
       "      <th>00 showing</th>\n",
       "      <th>00 sunday</th>\n",
       "      <th>00 wasn</th>\n",
       "      <th>000</th>\n",
       "      <th>000 000</th>\n",
       "      <th>...</th>\n",
       "      <th>zwick the</th>\n",
       "      <th>zwick thinks</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zwigoff brilliant</th>\n",
       "      <th>zwigoff superb</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zycie masterfully</th>\n",
       "      <th>zycie za</th>\n",
       "      <th>zzzzzzz</th>\n",
       "      <th>zzzzzzz critique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 495294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  00 am  00 feet  00 for  00 if  00 showing  00 sunday  00 wasn  000  \\\n",
       "0     0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "1     0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "2     0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "3     0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "4     0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "...   ...    ...      ...     ...    ...         ...        ...      ...  ...   \n",
       "1795  0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "1796  0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "1797  0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "1798  0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "1799  0.0    0.0      0.0     0.0    0.0         0.0        0.0      0.0  0.0   \n",
       "\n",
       "      000 000  ...  zwick the  zwick thinks  zwigoff  zwigoff brilliant  \\\n",
       "0         0.0  ...        0.0           0.0      0.0                0.0   \n",
       "1         0.0  ...        0.0           0.0      0.0                0.0   \n",
       "2         0.0  ...        0.0           0.0      0.0                0.0   \n",
       "3         0.0  ...        0.0           0.0      0.0                0.0   \n",
       "4         0.0  ...        0.0           0.0      0.0                0.0   \n",
       "...       ...  ...        ...           ...      ...                ...   \n",
       "1795      0.0  ...        0.0           0.0      0.0                0.0   \n",
       "1796      0.0  ...        0.0           0.0      0.0                0.0   \n",
       "1797      0.0  ...        0.0           0.0      0.0                0.0   \n",
       "1798      0.0  ...        0.0           0.0      0.0                0.0   \n",
       "1799      0.0  ...        0.0           0.0      0.0                0.0   \n",
       "\n",
       "      zwigoff superb  zycie  zycie masterfully  zycie za  zzzzzzz  \\\n",
       "0                0.0    0.0                0.0       0.0      0.0   \n",
       "1                0.0    0.0                0.0       0.0      0.0   \n",
       "2                0.0    0.0                0.0       0.0      0.0   \n",
       "3                0.0    0.0                0.0       0.0      0.0   \n",
       "4                0.0    0.0                0.0       0.0      0.0   \n",
       "...              ...    ...                ...       ...      ...   \n",
       "1795             0.0    0.0                0.0       0.0      0.0   \n",
       "1796             0.0    0.0                0.0       0.0      0.0   \n",
       "1797             0.0    0.0                0.0       0.0      0.0   \n",
       "1798             0.0    0.0                0.0       0.0      0.0   \n",
       "1799             0.0    0.0                0.0       0.0      0.0   \n",
       "\n",
       "      zzzzzzz critique  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "1795               0.0  \n",
       "1796               0.0  \n",
       "1797               0.0  \n",
       "1798               0.0  \n",
       "1799               0.0  \n",
       "\n",
       "[1800 rows x 495294 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a document-term matrix\n",
    "dtm = pandas.DataFrame(tfidf_values.toarray())\n",
    "\n",
    "# adding the column names to the matrix\n",
    "dtm.columns = vectorizer.get_feature_names()\n",
    "\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7132.233744"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "# approximate size of dtm in megabytes\n",
    "getsizeof(dtm)/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm['target_var'] = raw_data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the drop function returns all the columns in a data frame, except the specified ones\n",
    "x = dtm.drop(columns=[\"target_var\"])\n",
    "y = dtm[\"target_var\"]\n",
    "\n",
    "# 66% training and 34% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# creating a random forest\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# fittig the model\n",
    "model = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.761437908496732\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# predicting tariffs on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# printing overall accuracy on the test set\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
