{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ISA 414 - Managing Big Data\n","## Lecture 23 â€“ Spark (Part I)"]},{"cell_type":"markdown","metadata":{},"source":["### **Note: add %md on top of a cell in Databricks to create a markdown cell**"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6fb6f4d5-c801-41d8-b584-9f38b2824ac0","showTitle":false,"title":""}},"source":["#### Auxiliary functions"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"231cc727-a1ec-434d-bb79-a393fccd58a9","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import regexp_replace, trim, col, lower\n","\n","# removing punctuation; The resulting column is called 'sentence'\n","def removePunctuation(column):\n","    return trim(lower(regexp_replace(column, '([^\\s\\w_]|_)+', ''))).alias('sentence')  "]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"df0c7944-df9b-47d8-9de6-0988039af9ad","showTitle":false,"title":""}},"source":["#### Loading data"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"eb1ed01b-8edd-479f-9283-d3f9f2199c26","showTitle":false,"title":""}},"outputs":[],"source":["# change the filename here if necessary\n","fileName = \"/FileStore/tables/mobydick.txt\"\n","\n","# after the read.text() function, we have a data frame with a single column called 'value'\n","mobyDickDF = sqlContext.read.text(fileName).select(removePunctuation(col('value')))\n","\n","# print top 15 lines\n","mobyDickDF.show(15, truncate=False)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5a8e4d28-6a3f-4c45-a2d4-942d8ea51742","showTitle":false,"title":""}},"source":["#### Retrieving Words from Lines"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"659e3575-20f8-4ec5-8526-ee4b67a06269","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import split, explode\n","\n","# splitting words based on space; the resulting column is called 'split'\n","bookWordsSplitDF = (mobyDickDF.select(split(mobyDickDF.sentence, '\\s+').alias('split')))\n","\n","# explode() takes lists with many elements and create a row for each value \n","wordsSingleDF = (bookWordsSplitDF.select(explode(bookWordsSplitDF.split).alias('word')))\n","\n","# remove 'empty' words\n","bookWordsDF = wordsSingleDF.where(wordsSingleDF.word != '')\n","\n","bookWordsDF.show(15)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"89969a98-eff0-409a-a66c-798d7cfb2c92","showTitle":false,"title":""}},"source":["#### Counting Words"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"100339eb-8472-44fe-8d65-8454864b26bd","showTitle":false,"title":""}},"outputs":[],"source":["# grouping  by words and counting\n","WordsAndCountsDF = bookWordsDF.groupBy('word').count()\n","\n","# showing top words (descending order)\n","WordsAndCountsDF.orderBy(\"count\", ascending=0).show()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"ISA414","notebookOrigID":944482322175227,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
