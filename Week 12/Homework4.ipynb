{"cells":[{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/bol.csv\"\n\n# inferSchema := detect data types\n# header := whether first row contains column names\nraw_data = spark.read.load(file_location, format=\"csv\", inferSchema=\"true\", header=\"true\")\n\n# We keep raw_data intact because we will use it later\ndf = raw_data\n\n#adjust the column dimensions and create summed columns\nfrom pyspark.sql.functions import col\ndf = df.withColumn(\"PPR_1\",100 - col(\"PPR_1\"))\ndf = df.withColumn(\"PIR_1\",100 - col(\"PIR_1\"))\ndf = df.withColumn(\"PIR_2\",100 - col(\"PIR_2\"))\ndf = df.withColumn(\"PIR_3\",100 - col(\"PIR_3\"))\ndf = df.withColumn(\"PIR_4\",100 - col(\"PIR_4\"))\ndf = df.withColumn(\"PER_2\",100 - col(\"PER_2\"))\ndf = df.withColumn(\"PPR\", (col(\"PPR_1\") + col(\"PPR_2\") + col(\"PPR_3\") + col(\"PPR_4\") + col(\"PPR_5\")) / 5)\ndf = df.withColumn(\"PIR\", (col(\"PIR_1\") + col(\"PIR_2\") + col(\"PIR_3\") + col(\"PIR_4\") + col(\"PIR_5\")) / 5)\ndf = df.withColumn(\"PER\", (col(\"PER_1\") + col(\"PER_2\") + col(\"PER_3\") + col(\"PER_4\") + col(\"PER_5\")) / 5)\ndf = df.withColumn(\"PI\", (col(\"PI_1\") + col(\"PI_2\") + col(\"PI_3\") + col(\"PI_4\") + col(\"PI_5\")) / 5)\ndf = df.withColumn(\"PS\", (col(\"PS_1\") + col(\"PS_2\") + col(\"PS_3\") + col(\"PS_4\") + col(\"PS_5\")) / 5)\ndf = df.withColumn(\"PB\", (col(\"PB_1\") + col(\"PB_2\") + col(\"PB_3\") + col(\"PB_4\") + col(\"PB_5\")) / 5)\ndf = df.withColumn(\"WTB\", (col(\"WTB_1\") + col(\"WTB_2\") + col(\"WTB_3\") + col(\"WTB_4\") + col(\"WTB_5\")) / 5)\n\n#do the linear analysis and get statistics from the resulting regression\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\npredictors = [\"PPR\", \"PIR\", \"PER\", \"PI\", \"PS\", \"PB\"]\nassembler = VectorAssembler(inputCols=predictors, outputCol=\"predictors\")\ndf = assembler.transform(df)\nlr = LinearRegression(featuresCol = \"predictors\", labelCol=\"WTB\")\nmodel = lr.fit(df)\nprint(model.coefficients)\nprint(model.summary.pValues)\n\n#The perceived integrity, perceived security, and perceived benelovence were all significant factors in a customer's willingness buy from bol.com. We know that each of these three topics are important to customers as each of their p-values are significant at 0.0059, 0.0141, and 2.72 * 10^-7 respectively. Relatably, they also have the three biggest impacts per unit increase on a customer's willingness to buy at 0.283, 0.181 and 0.445 per unit respectively. If bol.com wants to increase its customer base and get more orders coming in, it should bolster its perceived integrity, perceived security and perceived benelovence. To make customers feel that the site has more integrity, bol.com could add a policy of something to the effect of \"love it or 100% money back guarantee\". By adding a policy like this one, it would let customers know that bol.com takes their customers' happiness and satisfaction into account, and make it appear as they are not only concerned about the bottom line. Bol.com could make customers feel safer using their site if they added statements across their website that promote the efforts they put into securing their customer data. For example, when you enter your username and password to sign in, it could have a statement like \"Protected by OneSecure\" or whatever example replacement they might use for 'OneSecure' to let their customers know that as soon as they come to the site, their info is being safely guarded. Finally, to increase the perceived benevolence of bol.com to customers, bol.com could add a page to their website or perhaps a banner with testimonies from customers who had an issue with bol.com get resolved quickly and effectively. Knowing that even when other customers faced issues, they were able to easily get them resolved would increase the trust that customers have when dealing with the site."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd05d86d-4458-4eb5-b0da-5ad90eaa2d5e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[-0.07085604707544185,0.036090394355859035,-0.13331017474475726,0.2826744082131181,0.18050712726363805,0.44522159143059314]\n[0.24172750180668534, 0.5633429199478641, 0.06620459825012204, 0.005929142826983647, 0.014091926009233369, 2.7275101222024034e-07, 0.187103123615892]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[-0.07085604707544185,0.036090394355859035,-0.13331017474475726,0.2826744082131181,0.18050712726363805,0.44522159143059314]\n[0.24172750180668534, 0.5633429199478641, 0.06620459825012204, 0.005929142826983647, 0.014091926009233369, 2.7275101222024034e-07, 0.187103123615892]\n"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Homework4","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2387696228208306}},"nbformat":4,"nbformat_minor":0}
