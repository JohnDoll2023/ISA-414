{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISA 414 - Managing Big Data\n",
    "## Lecture 17 â€“ Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "\n",
    "# retrieving the response in JSON; the \"headers\" argument tells Reddit \"who\" is asking for data to prevent \"too many requests\" errors\n",
    "response = requests.get(\"https://www.reddit.com/r/miamioh.json\",  headers = {'User-agent': 'ISA 514/414'})\n",
    "response = response.json()\n",
    "\n",
    "# creating an empty data frame\n",
    "df = pandas.DataFrame()\n",
    "\n",
    "# for each post in the data -> children branch\n",
    "for post in response[\"data\"][\"children\"]:\n",
    "\n",
    "    # create a row for the values associated with the 'data' key\n",
    "    json_to_row = pandas.json_normalize(post[\"data\"])\n",
    "\n",
    "    # append data to empty data frame\n",
    "    df = df.append(json_to_row)\n",
    "\n",
    "# save data to csv to help visualization \n",
    "df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "\n",
    "# retrieving the response in JSON; the \"headers\" argument tells Reddit \"who\" is asking for data to prevent \"too many requests\" errors\n",
    "response = requests.get(\"https://www.reddit.com/r/miamioh/comments/oygda9/email_from_president_crawford_to_all_faculty.json\", headers = {'User-agent': 'ISA 514/414'})\n",
    "response = response.json()\n",
    "\n",
    "# retrieving post info: first key-value pair, i.e., position 0 in the JSON file\n",
    "df_post = pandas.json_normalize(response[0][\"data\"][\"children\"][0][\"data\"])\n",
    "\n",
    "# creating an empty data frame\n",
    "df_comments = pandas.DataFrame()\n",
    "\n",
    "# retrieving comments info: second key-value pair, i.e., position 1 in the JSON file\n",
    "# for each post in the data -> children branch\n",
    "for post in response[1][\"data\"][\"children\"]:\n",
    "\n",
    "    # create a row for the values associated with the 'data' key\n",
    "    json_to_row = pandas.json_normalize(post[\"data\"])\n",
    "\n",
    "    # append data to empty data frame\n",
    "    df_comments = df_comments.append(json_to_row)\n",
    "\n",
    "# save data to csv to help visualization \n",
    "df_comments.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 21: Make sure you install tweepy by running *pip install tweepy* in the terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# creating the 4 keys - PLEASE DON'T SHARE THESE WITH OTHERS OUTSIDE THE COURSE\n",
    "consumer_key = \"zs0yFmnhHnfjnIS3eOXU9AtJU\"\n",
    "consumer_secret = \"dbsGwYqw4jxgpiuY1kQH5Yf4dECdk9JCsJVAKaYH1ExUAoVz9B\"\n",
    "access_token = \"1357013845647101955-t5k1nAOzGIKb6oohfw99l7F2aOVIJp\"\n",
    "access_token_secret = \"DkgJun3wp8zdVSmUDr6rEYF82deUyr9EIipjcnmFPzDzl\"\n",
    "\n",
    "# authenticating\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "response = api.rate_limit_status()\n",
    "\n",
    "remaining_searches = response['resources']['search']['/search/tweets']\n",
    "\n",
    "# printing the search-related constraints\n",
    "print(remaining_searches)\n",
    "print(\"Reset time: \" + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(remaining_searches['reset'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = api.search_tweets(q=\"Microsoft\", lang=\"en\", count=100)\n",
    "\n",
    "# creating an empty list\n",
    "df = []\n",
    "\n",
    "# adding elements to the list\n",
    "# note that each element has two values\n",
    "for tweet in search_results:\n",
    "    df.append([tweet.user.name, tweet.user.screen_name, tweet.text, tweet.created_at, tweet.favorite_count])\n",
    "    \n",
    "# creating a data frame\n",
    "df = pandas.DataFrame(df)\n",
    "df.columns = [\"Username\", \"Screen Name\", \"Text\", \"Created At\", \"Likes\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = api.get_followers(screen_name = \"miamiuniversity\", count = 100)\n",
    "\n",
    "# creating an empty list\n",
    "df = []\n",
    "\n",
    "# adding elements to the list\n",
    "# note that each element has four values\n",
    "for follower in search_results:\n",
    "    df.append([follower.name, follower.description, \n",
    "               follower.screen_name, follower.location])\n",
    "\n",
    "# creating a data frame    \n",
    "df = pandas.DataFrame(df)\n",
    "df.columns = [\"Name\", \"Description\", \"Username\", \"Location\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.available_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2380358 is the code for Cincinnati\n",
    "response = api.get_place_trends(2380358)\n",
    "\n",
    "# creating an empty data frame\n",
    "df = pandas.DataFrame()\n",
    "\n",
    "for trend in response[0][\"trends\"]:\n",
    "\n",
    "    # create a row for the values associated with the 'data' key\n",
    "    json_to_row = pandas.json_normalize(trend)\n",
    "\n",
    "    # append data to empty data frame\n",
    "    df = df.append(json_to_row)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slide 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = api.user_timeline(screen_name = \"microsoft\", count = 1000, exclude_replies = True)\n",
    "\n",
    "# creating an empty list\n",
    "df = []\n",
    "\n",
    "# adding elements to the list\n",
    "# note that each element has three values\n",
    "for tweet in search_results:\n",
    "    df.append([tweet.created_at, tweet.text, tweet.favorite_count])\n",
    "\n",
    "# creating a data frame    \n",
    "df = pandas.DataFrame(df)\n",
    "df.columns = [\"Created at\", \"Text\", \"Favorite Count\"]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f581d018a546ff485bbe9afc04fe925a6dbac1faa56a245c7e60b68a5d49f26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
