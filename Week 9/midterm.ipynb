{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Project\n",
    "## Spencer Townes, John Doll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New tweet:  #ISA414 I love love love love love this course  Score:  1\n",
      "New tweet:  #ISA414 I really hate this course  Score:  -1\n",
      "New tweet:  #ISA414 I love this course  Score:  1\n",
      "New tweet:  #ISA414 I love this course  Score:  1\n",
      "Cumulative score at  2021-10-19 14:57:23.508797 :  2\n",
      "Cumulative score at  2021-10-19 14:57:33.787260 :  2\n",
      "Cumulative score at  2021-10-19 14:57:44.259279 :  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/88/l0rstcb91tn63mf9tdbd364r0000gn/T/ipykernel_34807/1309127406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cumulative score at \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# sleeping for 10 seconds to avoid too many Twitter queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import the required modules \n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import tweepy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# connect to the Twitter API  \n",
    "consumer_key = \"zs0yFmnhHnfjnIS3eOXU9AtJU\"\n",
    "consumer_secret = \"dbsGwYqw4jxgpiuY1kQH5Yf4dECdk9JCsJVAKaYH1ExUAoVz9B\"\n",
    "access_token = \"1357013845647101955-t5k1nAOzGIKb6oohfw99l7F2aOVIJp\"\n",
    "access_token_secret = \"DkgJun3wp8zdVSmUDr6rEYF82deUyr9EIipjcnmFPzDzl\"\n",
    "\n",
    "# authenticating\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# load the lists of positive and negative words \n",
    "file = open('positive-words.txt', 'r')\n",
    "positive_words = file.read().splitlines() \n",
    "\n",
    "file = open('negative-words.txt', 'r')\n",
    "negative_words = file.read().splitlines() \n",
    "\n",
    "# create tracking variables for tweet iteration\n",
    "cumulative_score = 0\n",
    "tweets = []\n",
    "\n",
    "# starting the infinite loop \n",
    "while True:      \n",
    "    # retrieve 5 tweets \n",
    "    search_results  = api.search_tweets(q=\"#ISA414\", lang=\"en\", count=5) \n",
    "\n",
    "    # for each tweet in my search \n",
    "    for tweet in search_results: \n",
    "        \n",
    "        # verify whether each individual tweet is new \n",
    "        if tweet.id not in tweets : \n",
    "            tweets.append(tweet.id)\n",
    "            # create a corpus of a single tweet\n",
    "            corpus = tweet.text.lower().split()\n",
    "\n",
    "            # calculate the score value  \n",
    "            count_vect = CountVectorizer(stop_words='english')\n",
    "            dtm = count_vect.fit_transform(corpus)\n",
    "\n",
    "            # vectorize the words\n",
    "            tweet_words = count_vect.get_feature_names()\n",
    "\n",
    "            # Calculate the score value  \n",
    "            count_positive_words = [positive_words.count(word) for word in tweet_words]\n",
    "            count_negative_words = [negative_words.count(word) for word in tweet_words]\n",
    "\n",
    "            # Get the sentiment score\n",
    "            score = sum(count_positive_words) - sum(count_negative_words)\n",
    " \n",
    "            # updating cumulative_score \n",
    "            cumulative_score = cumulative_score + score  \n",
    "            # print new tweets and their scores \n",
    "            print(\"New tweet: \", tweet.text, \" Score: \", score)\n",
    "\n",
    "    # printing current cumulative_score     \n",
    "    print(\"Cumulative score at \", datetime.now(), \": \", cumulative_score)\n",
    "    # sleeping for 10 seconds to avoid too many Twitter queries \n",
    "    sleep(10) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
